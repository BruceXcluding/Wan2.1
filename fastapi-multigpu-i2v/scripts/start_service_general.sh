#!/bin/bash

echo "üöÄ Starting Universal Multi-GPU Video Generation API..."

# Ëé∑ÂèñËÑöÊú¨ÊâÄÂú®ÁõÆÂΩïÂíåÈ°πÁõÆÊ†πÁõÆÂΩï
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

echo "üìÇ Project root: $PROJECT_ROOT"
echo "üìÇ Script directory: $SCRIPT_DIR"

# ËÆæÁΩÆ Python Ë∑ØÂæÑÔºàÂú®ËÆæÂ§áÊ£ÄÊµã‰πãÂâçÔºâ
export PYTHONPATH="$PROJECT_ROOT/src:$PROJECT_ROOT:${PYTHONPATH}"
echo "üêç PYTHONPATH: $PYTHONPATH"

# Ëá™Âä®Ê£ÄÊµãËÆæÂ§áÁ±ªÂûã
echo "üîç Detecting hardware devices..."
python3 -c "
import sys
import os

# Á°Æ‰øùË∑ØÂæÑÊ≠£Á°Æ
project_root = '$PROJECT_ROOT'
src_path = os.path.join(project_root, 'src')

# Ê£ÄÊü•Ë∑ØÂæÑÊòØÂê¶Â≠òÂú®
if not os.path.exists(src_path):
    print(f'Error: src path does not exist: {src_path}', file=sys.stderr)
    print('DETECTED_DEVICE=cuda')
    print('DEVICE_COUNT=1')
    exit()

# Ê∑ªÂä†Âà∞ Python Ë∑ØÂæÑ
if src_path not in sys.path:
    sys.path.insert(0, src_path)

print(f'DEBUG: Python paths added: {src_path}', file=sys.stderr)
print(f'DEBUG: Current sys.path: {sys.path[:3]}...', file=sys.stderr)

try:
    # Â∞ùËØïÂØºÂÖ•ËÆæÂ§áÊ£ÄÊµãÂô®
    from utils.device_detector import device_detector
    device_type, device_count = device_detector.detect_device()
    print(f'DETECTED_DEVICE={device_type.value}')
    print(f'DEVICE_COUNT={device_count}')
    print(f'DEBUG: Successfully detected {device_type.value} with {device_count} devices', file=sys.stderr)
except ImportError as e:
    print(f'Import error: {e}', file=sys.stderr)
    # Â∞ùËØïÁÆÄÂçïÁöÑËÆæÂ§áÊ£ÄÊµã
    try:
        import torch
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            print(f'DETECTED_DEVICE=cuda')
            print(f'DEVICE_COUNT={device_count}')
            print(f'DEBUG: Fallback CUDA detection: {device_count} devices', file=sys.stderr)
        else:
            print('DETECTED_DEVICE=cuda')
            print('DEVICE_COUNT=1')
            print('DEBUG: No CUDA available, using default', file=sys.stderr)
    except:
        print('DETECTED_DEVICE=cuda')
        print('DEVICE_COUNT=1')
        print('DEBUG: Fallback to default values', file=sys.stderr)
except Exception as e:
    print(f'Detection error: {e}', file=sys.stderr)
    print('DETECTED_DEVICE=cuda')
    print('DEVICE_COUNT=1')
" > device_info.tmp 2> device_debug.log

# Ê£ÄÊü•ËÆæÂ§áÊ£ÄÊµãÊòØÂê¶ÊàêÂäü
if [ ! -f device_info.tmp ] || [ ! -s device_info.tmp ]; then
    echo "‚ö†Ô∏è  Device detection failed, using defaults..."
    echo "DETECTED_DEVICE=cuda" > device_info.tmp
    echo "DEVICE_COUNT=1" >> device_info.tmp
fi

# ÊòæÁ§∫Ë∞ÉËØï‰ø°ÊÅØ
if [ -f device_debug.log ]; then
    echo "üîç Device detection debug info:"
    cat device_debug.log
    rm device_debug.log
fi

source device_info.tmp
rm device_info.tmp

echo "‚úÖ Detected device: $DETECTED_DEVICE with $DEVICE_COUNT devices"

# ËÆæÁΩÆÈÄöÁî®ÁéØÂ¢ÉÂèòÈáè
export TOKENIZERS_PARALLELISM=false
export MASTER_ADDR=${MASTER_ADDR:-"127.0.0.1"}
export MASTER_PORT=${MASTER_PORT:-"29500"}

# Ê†πÊçÆËÆæÂ§áÁ±ªÂûãËÆæÁΩÆÁâπÂÆöÁéØÂ¢ÉÂèòÈáè
if [ "$DETECTED_DEVICE" = "npu" ]; then
    echo "‚öôÔ∏è  Configuring for NPU (Ascend)..."
    export ALGO=0
    export PYTORCH_NPU_ALLOC_CONF='expandable_segments:True'
    export TASK_QUEUE_ENABLE=2
    export CPU_AFFINITY_CONF=1
    export HCCL_TIMEOUT=3600
    export HCCL_CONNECT_TIMEOUT=1200
    export HCCL_BUFFSIZE=256
    export ASCEND_LAUNCH_BLOCKING=0
    export ASCEND_GLOBAL_LOG_LEVEL=1
    
    # Âä®ÊÄÅËÆæÁΩÆÂèØËßÅËÆæÂ§á
    if [ $DEVICE_COUNT -gt 0 ]; then
        DEVICE_LIST=$(seq -s, 0 $((DEVICE_COUNT-1)))
        export NPU_VISIBLE_DEVICES=$DEVICE_LIST
        export ASCEND_RT_VISIBLE_DEVICES=$DEVICE_LIST
        echo "üéØ NPU devices: $DEVICE_LIST"
    fi
    
elif [ "$DETECTED_DEVICE" = "cuda" ]; then
    echo "‚öôÔ∏è  Configuring for CUDA (NVIDIA)..."
    export NCCL_TIMEOUT=3600
    export CUDA_LAUNCH_BLOCKING=0
    export NCCL_DEBUG=${NCCL_DEBUG:-"WARN"}
    export NCCL_IB_DISABLE=1
    export NCCL_P2P_DISABLE=0
    
    # Âä®ÊÄÅËÆæÁΩÆÂèØËßÅËÆæÂ§á
    if [ $DEVICE_COUNT -gt 0 ]; then
        DEVICE_LIST=$(seq -s, 0 $((DEVICE_COUNT-1)))
        export CUDA_VISIBLE_DEVICES=$DEVICE_LIST
        echo "üéØ CUDA devices: $DEVICE_LIST"
    fi
    
else
    echo "‚ùå Unsupported device: $DETECTED_DEVICE"
    echo "üí° Supported devices: npu, cuda"
    exit 1
fi

# Ê®°ÂûãÂíåÊúçÂä°ÈÖçÁΩÆ
export MODEL_CKPT_DIR=${MODEL_CKPT_DIR:-"/data/models/modelscope/hub/Wan-AI/Wan2.1-I2V-14B-720P"}
export MODEL_TASK=${MODEL_TASK:-"i2v-14B"}
export DEFAULT_SIZE=${DEFAULT_SIZE:-"1280*720"}
export DEFAULT_FRAME_NUM=${DEFAULT_FRAME_NUM:-"81"}
export DEFAULT_SAMPLE_STEPS=${DEFAULT_SAMPLE_STEPS:-"30"}

# ÂèØÈÖçÁΩÆÁöÑÊ®°ÂûãÈÄâÈ°π
export T5_CPU=${T5_CPU:-"false"}
export DIT_FSDP=${DIT_FSDP:-"true"}
export T5_FSDP=${T5_FSDP:-"false"}
export VAE_PARALLEL=${VAE_PARALLEL:-"true"}
export CFG_SIZE=${CFG_SIZE:-"1"}
export ULYSSES_SIZE=${ULYSSES_SIZE:-"8"}

# ÊÄßËÉΩ‰ºòÂåñÈÖçÁΩÆ
export USE_ATTENTION_CACHE=${USE_ATTENTION_CACHE:-"true"}
export CACHE_START_STEP=${CACHE_START_STEP:-"12"}
export CACHE_INTERVAL=${CACHE_INTERVAL:-"4"}
export CACHE_END_STEP=${CACHE_END_STEP:-"37"}

# ‰∏öÂä°ÈÖçÁΩÆÔºàÊ†πÊçÆËÆæÂ§áÂíå T5 Ê®°ÂºèËá™Âä®Ë∞ÉÊï¥Ôºâ
if [ "$T5_CPU" = "true" ] || [ "$DETECTED_DEVICE" = "npu" ]; then
    export MAX_CONCURRENT_TASKS=${MAX_CONCURRENT_TASKS:-"2"}
    export TASK_TIMEOUT=${TASK_TIMEOUT:-"2400"}  # 40ÂàÜÈíü
    export OMP_NUM_THREADS=${OMP_NUM_THREADS:-"16"}  # T5 CPU ÈúÄË¶ÅÊõ¥Â§öÁ∫øÁ®ã
    export MKL_NUM_THREADS=${MKL_NUM_THREADS:-"16"}
    export OPENBLAS_NUM_THREADS=${OPENBLAS_NUM_THREADS:-"16"}
else
    export MAX_CONCURRENT_TASKS=${MAX_CONCURRENT_TASKS:-"4"}
    export TASK_TIMEOUT=${TASK_TIMEOUT:-"1800"}  # 30ÂàÜÈíü
    export OMP_NUM_THREADS=${OMP_NUM_THREADS:-"8"}
    export MKL_NUM_THREADS=${MKL_NUM_THREADS:-"8"}
    export OPENBLAS_NUM_THREADS=${OPENBLAS_NUM_THREADS:-"8"}
fi

# ÊúçÂä°ÈÖçÁΩÆ
export SERVER_HOST=${SERVER_HOST:-"0.0.0.0"}
export SERVER_PORT=${SERVER_PORT:-"8088"}
export CLEANUP_INTERVAL=${CLEANUP_INTERVAL:-"300"}
export MAX_OUTPUT_DIR_SIZE=${MAX_OUTPUT_DIR_SIZE:-"50"}
export ALLOWED_HOSTS=${ALLOWED_HOSTS:-"*"}

echo "üìã Configuration Summary:"
echo "  - Device: $DETECTED_DEVICE ($DEVICE_COUNT cards)"
echo "  - Model Path: $MODEL_CKPT_DIR"
echo "  - T5 CPU Mode: $T5_CPU"
echo "  - DIT FSDP: $DIT_FSDP"
echo "  - VAE Parallel: $VAE_PARALLEL"
echo "  - Ulysses Size: $ULYSSES_SIZE"
echo "  - Attention Cache: $USE_ATTENTION_CACHE"
echo "  - Max Concurrent: $MAX_CONCURRENT_TASKS"
echo "  - Task Timeout: ${TASK_TIMEOUT}s"
echo "  - Server: $SERVER_HOST:$SERVER_PORT"
echo "  - CPU Threads: $OMP_NUM_THREADS"

# È™åËØÅÈ°πÁõÆÁªìÊûÑ
echo "üîç Verifying project structure..."
if [ ! -f "$PROJECT_ROOT/src/utils/device_detector.py" ]; then
    echo "‚ö†Ô∏è  device_detector.py not found at: $PROJECT_ROOT/src/utils/device_detector.py"
    echo "üí° Creating minimal device detector..."
    
    mkdir -p "$PROJECT_ROOT/src/utils"
    cat > "$PROJECT_ROOT/src/utils/__init__.py" << 'EOF'
# Utils package
EOF

    cat > "$PROJECT_ROOT/src/utils/device_detector.py" << 'EOF'
"""
ËÆæÂ§áËá™Âä®Ê£ÄÊµãÂ∑•ÂÖ∑
"""
from enum import Enum
from typing import Tuple

class DeviceType(Enum):
    NPU = "npu"
    CUDA = "cuda"

class DeviceDetector:
    """ËÆæÂ§áÊ£ÄÊµãÂô®"""
    
    def detect_device(self) -> Tuple[DeviceType, int]:
        """Ê£ÄÊµãÂèØÁî®ËÆæÂ§á"""
        # ‰ºòÂÖàÊ£ÄÊµã NPU
        try:
            import torch_npu
            if torch_npu.npu.is_available():
                device_count = torch_npu.npu.device_count()
                return DeviceType.NPU, device_count
        except ImportError:
            pass
        
        # Ê£ÄÊµã CUDA
        try:
            import torch
            if torch.cuda.is_available():
                device_count = torch.cuda.device_count()
                return DeviceType.CUDA, device_count
        except ImportError:
            pass
        
        # ÈªòËÆ§ËøîÂõûÂçïÂç° CUDA
        return DeviceType.CUDA, 1

# ÂÖ®Â±ÄÂÆû‰æã
device_detector = DeviceDetector()
EOF
    echo "‚úÖ Created minimal device detector"
fi

# È™åËØÅÊ®°ÂûãË∑ØÂæÑ
if [ ! -d "$MODEL_CKPT_DIR" ]; then
    echo "‚ö†Ô∏è  Model directory not found: $MODEL_CKPT_DIR"
    echo "üí° Please set MODEL_CKPT_DIR environment variable"
    echo "üí° Example: export MODEL_CKPT_DIR=/path/to/your/model"
fi

# Ê∏ÖÁêÜÊóßËøõÁ®ã
echo "üßπ Cleaning up old processes..."
pkill -f "i2v_api.py" 2>/dev/null || true
pkill -f "torchrun.*i2v_api" 2>/dev/null || true
sleep 5

# ÂàõÂª∫ÂøÖË¶ÅÁõÆÂΩï
echo "üìÅ Creating directories..."
mkdir -p "$PROJECT_ROOT/generated_videos"
mkdir -p "$PROJECT_ROOT/logs"

# ËÆæÁΩÆÂ∑•‰ΩúÁõÆÂΩï
cd "$PROJECT_ROOT"
echo "üìç Working directory: $(pwd)"

# Ê£ÄÊü•ËÆæÂ§áÁä∂ÊÄÅ
echo "üîç Checking device status..."
if [ "$DETECTED_DEVICE" = "npu" ]; then
    if command -v npu-smi &> /dev/null; then
        echo "NPU Status:"
        npu-smi info | head -10
    else
        echo "‚ö†Ô∏è  npu-smi not available"
    fi
elif [ "$DETECTED_DEVICE" = "cuda" ]; then
    if command -v nvidia-smi &> /dev/null; then
        echo "GPU Status:"
        nvidia-smi --query-gpu=index,name,memory.total,memory.used,utilization.gpu --format=csv
    else
        echo "‚ö†Ô∏è  nvidia-smi not available"
    fi
fi

# È™åËØÅ Python ÁéØÂ¢É
echo "üêç Checking Python environment..."
python3 -c "
import sys
import os
print(f'Python: {sys.version}')
print(f'Python executable: {sys.executable}')
print(f'Current working directory: {os.getcwd()}')
print(f'PYTHONPATH: {os.environ.get(\"PYTHONPATH\", \"Not set\")}')

# Ê£ÄÊü• src ÁõÆÂΩï
src_path = '$PROJECT_ROOT/src'
print(f'Checking src path: {src_path}')
print(f'Src path exists: {os.path.exists(src_path)}')

if os.path.exists(src_path):
    utils_path = os.path.join(src_path, 'utils')
    print(f'Utils path exists: {os.path.exists(utils_path)}')
    if os.path.exists(utils_path):
        detector_path = os.path.join(utils_path, 'device_detector.py')
        print(f'Device detector exists: {os.path.exists(detector_path)}')

try:
    if '$DETECTED_DEVICE' == 'npu':
        import torch_npu
        print(f'torch_npu available: {torch_npu.npu.is_available()}')
        if torch_npu.npu.is_available():
            print(f'NPU device count: {torch_npu.npu.device_count()}')
    elif '$DETECTED_DEVICE' == 'cuda':
        import torch
        print(f'PyTorch: {torch.__version__}')
        print(f'CUDA available: {torch.cuda.is_available()}')
        if torch.cuda.is_available():
            print(f'CUDA version: {torch.version.cuda}')
            print(f'GPU device count: {torch.cuda.device_count()}')
except ImportError as e:
    print(f'‚ùå Import error: {e}')
    sys.exit(1)
except Exception as e:
    print(f'‚ö†Ô∏è  Environment check warning: {e}')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Python environment check failed!"
    echo "üí° Please check your PyTorch installation"
    exit 1
fi

# Ê∏ÖÁêÜËÆæÂ§áÁºìÂ≠ò
echo "üóëÔ∏è  Clearing device cache..."
python3 -c "
try:
    if '$DETECTED_DEVICE' == 'npu':
        import torch_npu
        torch_npu.npu.empty_cache()
        print('‚úÖ NPU cache cleared')
    elif '$DETECTED_DEVICE' == 'cuda':
        import torch
        torch.cuda.empty_cache()
        print('‚úÖ CUDA cache cleared')
except Exception as e:
    print(f'‚ö†Ô∏è  Cache clear warning: {e}')
"

# ËÆæÁΩÆ‰ø°Âè∑Â§ÑÁêÜ
trap 'echo "üõë Stopping service..."; pkill -f "torchrun.*i2v_api"; exit 0' INT TERM

# ÂêØÂä®ÂàÜÂ∏ÉÂºèÊúçÂä°
echo ""
echo "üöÄ Starting $DEVICE_COUNT-card distributed service on $DETECTED_DEVICE..."
echo "üì° Master: $MASTER_ADDR:$MASTER_PORT"
echo "üåê Server will start on http://$SERVER_HOST:$SERVER_PORT"
echo "üìñ API docs: http://$SERVER_HOST:$SERVER_PORT/docs"
echo ""

# ÂêØÂä®ÊúçÂä°Âπ∂ËÆ∞ÂΩïÊó•Âøó
LOG_FILE="$PROJECT_ROOT/logs/${DETECTED_DEVICE}_service_$(date +%Y%m%d_%H%M%S).log"

torchrun \
    --nproc_per_node=$DEVICE_COUNT \
    --master_addr=$MASTER_ADDR \
    --master_port=$MASTER_PORT \
    --nnodes=1 \
    --node_rank=0 \
    src/i2v_api.py 2>&1 | tee "$LOG_FILE"

echo "üèÅ Service stopped. Logs saved to: $LOG_FILE"