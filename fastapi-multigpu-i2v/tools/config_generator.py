#!/usr/bin/env python3
"""
é…ç½®ç”Ÿæˆå™¨å·¥å…·
æ ¹æ®ç¡¬ä»¶ç¯å¢ƒå’Œéœ€æ±‚è‡ªåŠ¨ç”Ÿæˆæœ€ä¼˜é…ç½®
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class HardwareInfo:
    """ç¡¬ä»¶ä¿¡æ¯"""
    device_type: str
    device_count: int
    memory_per_device: float  # GB
    total_memory: float      # GB
    cpu_cores: int
    system_memory: float     # GB

@dataclass
class ServiceConfig:
    """æœåŠ¡é…ç½®"""
    # æ¨¡å‹é…ç½®
    model_path: str
    t5_cpu: bool
    dit_fsdp: bool
    t5_fsdp: bool
    vae_parallel: bool
    cfg_size: int
    ulysses_size: int
    
    # æ€§èƒ½ä¼˜åŒ–
    use_attentioncache: bool
    cache_start_step: int
    cache_interval: int
    cache_end_step: int
    
    # ä¸šåŠ¡é…ç½®
    max_concurrent_tasks: int
    task_timeout: int
    server_port: int
    
    # ç¯å¢ƒå˜é‡
    environment_vars: Dict[str, str]

class ConfigGenerator:
    """é…ç½®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.hardware_info: Optional[HardwareInfo] = None
        self.config_templates = {
            "development": {
                "description": "å¼€å‘ç¯å¢ƒ - å¿«é€Ÿå¯åŠ¨ï¼Œè¾ƒä½èµ„æºå ç”¨",
                "max_concurrent_factor": 0.5,
                "use_optimization": False,
                "timeout_factor": 1.0
            },
            "production": {
                "description": "ç”Ÿäº§ç¯å¢ƒ - æœ€ä¼˜æ€§èƒ½å’Œç¨³å®šæ€§",
                "max_concurrent_factor": 1.0,
                "use_optimization": True,
                "timeout_factor": 1.5
            },
            "testing": {
                "description": "æµ‹è¯•ç¯å¢ƒ - å¿«é€Ÿå“åº”ï¼Œé€‚åˆè‡ªåŠ¨åŒ–æµ‹è¯•",
                "max_concurrent_factor": 0.3,
                "use_optimization": False,
                "timeout_factor": 0.8
            }
        }
    
    def detect_hardware(self) -> HardwareInfo:
        """æ£€æµ‹ç¡¬ä»¶ä¿¡æ¯"""
        print("ğŸ” Detecting hardware information...")
        
        try:
            # æ£€æµ‹è®¾å¤‡ç±»å‹å’Œæ•°é‡
            from utils.device_detector import device_detector
            device_type, device_count = device_detector.detect_device()
            
            # æ£€æµ‹è®¾å¤‡å†…å­˜
            memory_per_device = self._get_device_memory(device_type.value)
            total_memory = memory_per_device * device_count
            
            # æ£€æµ‹CPUä¿¡æ¯
            cpu_cores = os.cpu_count() or 1
            
            # æ£€æµ‹ç³»ç»Ÿå†…å­˜
            system_memory = self._get_system_memory()
            
            hardware_info = HardwareInfo(
                device_type=device_type.value,
                device_count=device_count,
                memory_per_device=memory_per_device,
                total_memory=total_memory,
                cpu_cores=cpu_cores,
                system_memory=system_memory
            )
            
            self.hardware_info = hardware_info
            
            print(f"âœ… Hardware detected:")
            print(f"   Device: {device_type.value} x {device_count}")
            print(f"   Memory: {memory_per_device:.1f}GB per device ({total_memory:.1f}GB total)")
            print(f"   CPU: {cpu_cores} cores")
            print(f"   System Memory: {system_memory:.1f}GB")
            
            return hardware_info
            
        except Exception as e:
            logger.error(f"Hardware detection failed: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return HardwareInfo(
                device_type="unknown",
                device_count=1,
                memory_per_device=32.0,
                total_memory=32.0,
                cpu_cores=16,
                system_memory=64.0
            )
    
    def _get_device_memory(self, device_type: str) -> float:
        """è·å–è®¾å¤‡å†…å­˜å¤§å°ï¼ˆGBï¼‰"""
        try:
            if device_type == "npu":
                # NPU å†…å­˜æ£€æµ‹
                import torch_npu
                if torch_npu.npu.is_available():
                    # å°è¯•è·å– NPU å†…å­˜ä¿¡æ¯ï¼ˆå¯èƒ½éœ€è¦ç‰¹å®šAPIï¼‰
                    return 32.0  # é»˜è®¤ 32GBï¼Œå®é™…åº”é€šè¿‡ NPU API è·å–
            elif device_type == "cuda":
                # CUDA å†…å­˜æ£€æµ‹
                import torch
                if torch.cuda.is_available():
                    props = torch.cuda.get_device_properties(0)
                    return props.total_memory / (1024**3)  # è½¬æ¢ä¸ºGB
        except Exception as e:
            logger.warning(f"Failed to get device memory: {str(e)}")
        
        return 32.0  # é»˜è®¤å€¼
    
    def _get_system_memory(self) -> float:
        """è·å–ç³»ç»Ÿå†…å­˜å¤§å°ï¼ˆGBï¼‰"""
        try:
            import psutil
            return psutil.virtual_memory().total / (1024**3)
        except ImportError:
            # å°è¯•é€šè¿‡å…¶ä»–æ–¹å¼è·å–
            try:
                # Linux
                with open('/proc/meminfo', 'r') as f:
                    for line in f:
                        if 'MemTotal' in line:
                            # æå–æ•°å€¼ï¼ˆKBï¼‰å¹¶è½¬æ¢ä¸ºGB
                            memory_kb = int(line.split()[1])
                            return memory_kb / (1024**2)
            except:
                pass
        except Exception as e:
            logger.warning(f"Failed to get system memory: {str(e)}")
        
        return 64.0  # é»˜è®¤å€¼
    
    def generate_config(self, 
                       template: str = "production",
                       model_path: Optional[str] = None,
                       server_port: int = 8088,
                       custom_options: Optional[Dict[str, Any]] = None) -> ServiceConfig:
        """ç”ŸæˆæœåŠ¡é…ç½®"""
        
        if not self.hardware_info:
            self.detect_hardware()
        
        hw = self.hardware_info
        template_config = self.config_templates.get(template, self.config_templates["production"])
        
        print(f"ğŸ› ï¸  Generating {template} configuration...")
        print(f"   Template: {template_config['description']}")
        
        # åŸºç¡€é…ç½®
        model_path = model_path or "/data/models/modelscope/hub/Wan-AI/Wan2.1-I2V-14B-720P"
        
        # æ ¹æ®ç¡¬ä»¶é€‰æ‹© T5 CPU æ¨¡å¼
        t5_cpu = hw.device_type == "npu" or hw.memory_per_device < 24.0
        
        # åˆ†å¸ƒå¼é…ç½®
        dit_fsdp = hw.device_count > 1
        t5_fsdp = hw.device_count > 4 and not t5_cpu
        vae_parallel = hw.device_count > 1
        
        # å¹¶è¡Œé…ç½®
        cfg_size = min(2, hw.device_count)
        ulysses_size = min(8, hw.device_count)
        
        # æ€§èƒ½ä¼˜åŒ–
        use_optimization = template_config["use_optimization"]
        use_attentioncache = use_optimization and hw.memory_per_device >= 32.0
        
        # ä¸šåŠ¡é…ç½®
        base_concurrent = 2 if t5_cpu else min(5, int(hw.total_memory / 16))
        max_concurrent_tasks = int(base_concurrent * template_config["max_concurrent_factor"])
        max_concurrent_tasks = max(1, max_concurrent_tasks)
        
        base_timeout = 1800 if not t5_cpu else 2400
        task_timeout = int(base_timeout * template_config["timeout_factor"])
        
        # ç¯å¢ƒå˜é‡
        environment_vars = self._generate_environment_vars(hw, t5_cpu)
        
        config = ServiceConfig(
            model_path=model_path,
            t5_cpu=t5_cpu,
            dit_fsdp=dit_fsdp,
            t5_fsdp=t5_fsdp,
            vae_parallel=vae_parallel,
            cfg_size=cfg_size,
            ulysses_size=ulysses_size,
            use_attentioncache=use_attentioncache,
            cache_start_step=12 if use_attentioncache else 0,
            cache_interval=4 if use_attentioncache else 1,
            cache_end_step=37 if use_attentioncache else 40,
            max_concurrent_tasks=max_concurrent_tasks,
            task_timeout=task_timeout,
            server_port=server_port,
            environment_vars=environment_vars
        )
        
        # åº”ç”¨è‡ªå®šä¹‰é€‰é¡¹
        if custom_options:
            for key, value in custom_options.items():
                if hasattr(config, key):
                    setattr(config, key, value)
                    print(f"   Custom: {key} = {value}")
        
        return config
    
    def _generate_environment_vars(self, hw: HardwareInfo, t5_cpu: bool) -> Dict[str, str]:
        """ç”Ÿæˆç¯å¢ƒå˜é‡"""
        env_vars = {
            # é€šç”¨ç¯å¢ƒå˜é‡
            "TOKENIZERS_PARALLELISM": "false",
            "PYTHONPATH": "/workspace/Wan2.1:${PYTHONPATH}",
            "OMP_NUM_THREADS": str(min(16, hw.cpu_cores)),
            "MKL_NUM_THREADS": str(min(16, hw.cpu_cores)),
            "OPENBLAS_NUM_THREADS": str(min(16, hw.cpu_cores)),
        }
        
        # è®¾å¤‡ç‰¹å®šç¯å¢ƒå˜é‡
        if hw.device_type == "npu":
            env_vars.update({
                "ALGO": "0",
                "PYTORCH_NPU_ALLOC_CONF": "expandable_segments:True",
                "TASK_QUEUE_ENABLE": "2",
                "CPU_AFFINITY_CONF": "1",
                "HCCL_TIMEOUT": "3600",
                "HCCL_CONNECT_TIMEOUT": "1200",
                "HCCL_BUFFSIZE": "256",
                "ASCEND_LAUNCH_BLOCKING": "0",
                "ASCEND_GLOBAL_LOG_LEVEL": "1",
            })
            
            # è®¾ç½®å¯è§è®¾å¤‡
            if hw.device_count > 1:
                device_list = ",".join(str(i) for i in range(hw.device_count))
                env_vars["NPU_VISIBLE_DEVICES"] = device_list
                env_vars["ASCEND_RT_VISIBLE_DEVICES"] = device_list
        
        elif hw.device_type == "cuda":
            env_vars.update({
                "NCCL_TIMEOUT": "3600",
            })
            
            # è®¾ç½®å¯è§è®¾å¤‡
            if hw.device_count > 1:
                device_list = ",".join(str(i) for i in range(hw.device_count))
                env_vars["CUDA_VISIBLE_DEVICES"] = device_list
        
        return env_vars
    
    def print_config(self, config: ServiceConfig):
        """æ‰“å°é…ç½®ä¿¡æ¯"""
        print(f"\nğŸ“‹ Generated Configuration")
        print("=" * 60)
        
        print("Model Configuration:")
        print(f"  Model Path:        {config.model_path}")
        print(f"  T5 CPU Mode:       {config.t5_cpu}")
        print(f"  DiT FSDP:          {config.dit_fsdp}")
        print(f"  T5 FSDP:           {config.t5_fsdp}")
        print(f"  VAE Parallel:      {config.vae_parallel}")
        print(f"  CFG Size:          {config.cfg_size}")
        print(f"  Ulysses Size:      {config.ulysses_size}")
        
        print("\nPerformance Optimization:")
        print(f"  Attention Cache:   {config.use_attentioncache}")
        if config.use_attentioncache:
            print(f"  Cache Start Step:  {config.cache_start_step}")
            print(f"  Cache Interval:    {config.cache_interval}")
            print(f"  Cache End Step:    {config.cache_end_step}")
        
        print("\nBusiness Configuration:")
        print(f"  Max Concurrent:    {config.max_concurrent_tasks}")
        print(f"  Task Timeout:      {config.task_timeout}s")
        print(f"  Server Port:       {config.server_port}")
        
        print("\nEnvironment Variables:")
        for key, value in config.environment_vars.items():
            print(f"  {key}={value}")
    
    def export_env_file(self, config: ServiceConfig, filepath: str):
        """å¯¼å‡ºç¯å¢ƒå˜é‡æ–‡ä»¶"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write("# Auto-generated environment configuration\n")
                f.write(f"# Generated by ConfigGenerator\n\n")
                
                # æ¨¡å‹é…ç½®
                f.write("# Model Configuration\n")
                f.write(f'MODEL_CKPT_DIR="{config.model_path}"\n')
                f.write(f'T5_CPU="{str(config.t5_cpu).lower()}"\n')
                f.write(f'DIT_FSDP="{str(config.dit_fsdp).lower()}"\n')
                f.write(f'T5_FSDP="{str(config.t5_fsdp).lower()}"\n')
                f.write(f'VAE_PARALLEL="{str(config.vae_parallel).lower()}"\n')
                f.write(f'CFG_SIZE="{config.cfg_size}"\n')
                f.write(f'ULYSSES_SIZE="{config.ulysses_size}"\n\n')
                
                # æ€§èƒ½ä¼˜åŒ–
                f.write("# Performance Optimization\n")
                f.write(f'USE_ATTENTION_CACHE="{str(config.use_attentioncache).lower()}"\n')
                f.write(f'CACHE_START_STEP="{config.cache_start_step}"\n')
                f.write(f'CACHE_INTERVAL="{config.cache_interval}"\n')
                f.write(f'CACHE_END_STEP="{config.cache_end_step}"\n\n')
                
                # ä¸šåŠ¡é…ç½®
                f.write("# Business Configuration\n")
                f.write(f'MAX_CONCURRENT_TASKS="{config.max_concurrent_tasks}"\n')
                f.write(f'TASK_TIMEOUT="{config.task_timeout}"\n')
                f.write(f'SERVER_PORT="{config.server_port}"\n\n')
                
                # ç¯å¢ƒå˜é‡
                f.write("# Environment Variables\n")
                for key, value in config.environment_vars.items():
                    f.write(f'{key}="{value}"\n')
            
            print(f"âœ… Environment file exported to: {filepath}")
            
        except Exception as e:
            logger.error(f"Failed to export environment file: {str(e)}")
    
    def export_json(self, config: ServiceConfig, filepath: str):
        """å¯¼å‡º JSON é…ç½®æ–‡ä»¶"""
        try:
            config_dict = asdict(config)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(config_dict, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… JSON config exported to: {filepath}")
            
        except Exception as e:
            logger.error(f"Failed to export JSON config: {str(e)}")
    
    def generate_start_script(self, config: ServiceConfig, filepath: str):
        """ç”Ÿæˆå¯åŠ¨è„šæœ¬"""
        try:
            script_content = f"""#!/bin/bash
# Auto-generated service start script
# Generated by ConfigGenerator

set -e

echo "ğŸš€ Starting FastAPI Multi-GPU I2V Service"
echo "=========================================="

# Check if model directory exists
if [ ! -d "{config.model_path}" ]; then
    echo "âŒ Model directory not found: {config.model_path}"
    exit 1
fi

# Set environment variables
export MODEL_CKPT_DIR="{config.model_path}"
export T5_CPU="{str(config.t5_cpu).lower()}"
export DIT_FSDP="{str(config.dit_fsdp).lower()}"
export T5_FSDP="{str(config.t5_fsdp).lower()}"
export VAE_PARALLEL="{str(config.vae_parallel).lower()}"
export CFG_SIZE="{config.cfg_size}"
export ULYSSES_SIZE="{config.ulysses_size}"
export USE_ATTENTION_CACHE="{str(config.use_attentioncache).lower()}"
export CACHE_START_STEP="{config.cache_start_step}"
export CACHE_INTERVAL="{config.cache_interval}"
export CACHE_END_STEP="{config.cache_end_step}"
export MAX_CONCURRENT_TASKS="{config.max_concurrent_tasks}"
export TASK_TIMEOUT="{config.task_timeout}"
export SERVER_PORT="{config.server_port}"

# Set system environment variables
"""
            
            for key, value in config.environment_vars.items():
                script_content += f'export {key}="{value}"\n'
            
            hw_info = self.hardware_info
            if hw_info and hw_info.device_count > 1:
                # åˆ†å¸ƒå¼å¯åŠ¨
                script_content += f"""
# Start distributed service
echo "Starting {hw_info.device_count}-device distributed service..."
torchrun \\
    --nproc_per_node={hw_info.device_count} \\
    --master_addr=127.0.0.1 \\
    --master_port=29500 \\
    --nnodes=1 \\
    --node_rank=0 \\
    src/i2v_api.py
"""
            else:
                # å•å¡å¯åŠ¨
                script_content += """
# Start single device service
echo "Starting single-device service..."
python3 src/i2v_api.py
"""
            
            script_content += """
echo "Service stopped."
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(script_content)
            
            # è®¾ç½®æ‰§è¡Œæƒé™
            os.chmod(filepath, 0o755)
            
            print(f"âœ… Start script generated: {filepath}")
            
        except Exception as e:
            logger.error(f"Failed to generate start script: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Configuration Generator for Multi-GPU I2V Service")
    parser.add_argument("--template", choices=["development", "production", "testing"],
                       default="production", help="Configuration template")
    parser.add_argument("--model-path", type=str,
                       help="Model checkpoint directory path")
    parser.add_argument("--port", type=int, default=8088,
                       help="Server port")
    parser.add_argument("--output-dir", type=str, default=".",
                       help="Output directory for generated files")
    parser.add_argument("--export-env", action="store_true",
                       help="Export environment file (.env)")
    parser.add_argument("--export-json", action="store_true",
                       help="Export JSON configuration")
    parser.add_argument("--generate-script", action="store_true",
                       help="Generate start script")
    parser.add_argument("--custom", type=str,
                       help="Custom options as JSON string")
    
    args = parser.parse_args()
    
    try:
        generator = ConfigGenerator()
        
        # è§£æè‡ªå®šä¹‰é€‰é¡¹
        custom_options = None
        if args.custom:
            try:
                custom_options = json.loads(args.custom)
            except json.JSONDecodeError as e:
                logger.error(f"Invalid JSON in custom options: {str(e)}")
                return 1
        
        # ç”Ÿæˆé…ç½®
        config = generator.generate_config(
            template=args.template,
            model_path=args.model_path,
            server_port=args.port,
            custom_options=custom_options
        )
        
        # æ‰“å°é…ç½®
        generator.print_config(config)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(args.output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # å¯¼å‡ºæ–‡ä»¶
        if args.export_env:
            env_file = output_dir / f"config_{args.template}.env"
            generator.export_env_file(config, str(env_file))
        
        if args.export_json:
            json_file = output_dir / f"config_{args.template}.json"
            generator.export_json(config, str(json_file))
        
        if args.generate_script:
            script_file = output_dir / f"start_{args.template}.sh"
            generator.generate_start_script(config, str(script_file))
        
        print(f"\nğŸ‰ Configuration generation completed!")
        print(f"Template: {args.template}")
        print(f"Output directory: {output_dir.absolute()}")
        
        return 0
        
    except Exception as e:
        logger.error(f"Configuration generation failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())