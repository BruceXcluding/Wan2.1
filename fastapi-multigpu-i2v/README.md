# FastAPI Multi-GPU Video Generation API

åŸºäº Wan2.1-I2V-14B-720P æ¨¡å‹çš„å¤šå¡åˆ†å¸ƒå¼è§†é¢‘ç”Ÿæˆ API æœåŠ¡ï¼Œæ”¯æŒå›¾åƒåˆ°è§†é¢‘ï¼ˆImage-to-Videoï¼‰ç”Ÿæˆã€‚é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„è®¾è®¡ï¼Œæ”¯æŒåä¸ºæ˜‡è…¾ NPU å’Œ NVIDIA GPU å¤šå¡åˆ†å¸ƒå¼æ¨ç†ã€‚

## ğŸš€ é¡¹ç›®ç‰¹è‰²

- **ğŸ¯ å¤šå¡åˆ†å¸ƒå¼**ï¼šæ”¯æŒ NPU/GPU 8å¡å¹¶è¡Œæ¨ç†ï¼Œè‡ªåŠ¨è®¾å¤‡æ£€æµ‹
- **ğŸ§  T5 CPU æ¨¡å¼**ï¼šæ”¯æŒ T5 æ–‡æœ¬ç¼–ç å™¨åœ¨ CPU ä¸Šè¿è¡Œï¼ŒèŠ‚çœæ˜¾å­˜
- **ğŸ”„ å¼‚æ­¥å¤„ç†**ï¼šåŸºäº FastAPI çš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å’ŒçŠ¶æ€ç®¡ç†
- **ğŸ§© æ¨¡å—åŒ–æ¶æ„**ï¼šæ¸…æ™°çš„åˆ†å±‚è®¾è®¡ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- **âš¡ æ€§èƒ½ä¼˜åŒ–**ï¼šæ³¨æ„åŠ›ç¼“å­˜ã€VAEå¹¶è¡Œç­‰å¤šç§åŠ é€ŸæŠ€æœ¯
- **ğŸ“Š ä»»åŠ¡ç®¡ç†**ï¼šå®Œæ•´çš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†å’Œé˜Ÿåˆ—æ§åˆ¶
- **ğŸ›¡ï¸ å®¹é”™æœºåˆ¶**ï¼šå¥å£®çš„é”™è¯¯å¤„ç†å’Œèµ„æºæ¸…ç†
- **ğŸ”’ ä¼ä¸šçº§å®‰å…¨**ï¼šèµ„æºé™åˆ¶ã€å¹¶å‘æ§åˆ¶ã€å¼‚å¸¸å¤„ç†
- **ğŸ“ˆ ç›‘æ§è¿ç»´**ï¼šå¥åº·æ£€æŸ¥ã€æ€§èƒ½ç›‘æ§ã€è°ƒè¯•å·¥å…·
- **ğŸ›ï¸ çµæ´»é…ç½®**ï¼šé…ç½®ç”Ÿæˆå™¨ã€ç¯å¢ƒé¢„è®¾ã€å‚æ•°éªŒè¯

## ğŸ“ é¡¹ç›®ç»“æ„

```
fastapi-multigpu-i2v/
â”œâ”€â”€ src/                              # ğŸ¯ æ ¸å¿ƒæºç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ i2v_api.py                    # FastAPI ä¸»åº”ç”¨
â”‚   â”œâ”€â”€ schemas/                      # ğŸ“‹ æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ video.py                  # è¯·æ±‚/å“åº”æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ services/                     # ğŸ”§ ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ video_service.py          # ä»»åŠ¡ç®¡ç†æœåŠ¡
â”‚   â”œâ”€â”€ pipelines/                    # ğŸš€ æ¨ç†ç®¡é“
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_pipeline.py          # ç®¡é“åŸºç±»
â”‚   â”‚   â”œâ”€â”€ npu_pipeline.py           # NPU ç®¡é“å®ç°
â”‚   â”‚   â”œâ”€â”€ cuda_pipeline.py          # CUDA ç®¡é“å®ç°
â”‚   â”‚   â””â”€â”€ pipeline_factory.py       # ç®¡é“å·¥å‚
â”‚   â””â”€â”€ utils/                        # ğŸ› ï¸ å·¥å…·ç±»
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ device_detector.py        # è®¾å¤‡è‡ªåŠ¨æ£€æµ‹
â”œâ”€â”€ scripts/                          # ğŸ“œ å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ start_service_npu.sh          # NPU ä¸“ç”¨å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ start_service_cuda.sh         # CUDA ä¸“ç”¨å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ start_service_general.sh      # é€šç”¨å¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ debug/                        # ğŸ” è°ƒè¯•å·¥å…·
â”‚       â”œâ”€â”€ debug_t5_warmup.py        # T5 é¢„çƒ­è°ƒè¯•
â”‚       â”œâ”€â”€ debug_pipeline.py         # ç®¡é“è°ƒè¯•
â”‚       â”œâ”€â”€ debug_device.py           # è®¾å¤‡æ£€æµ‹è°ƒè¯•
â”‚       â””â”€â”€ debug_memory.py           # å†…å­˜ç›‘æ§è°ƒè¯•
â”œâ”€â”€ tools/                            # ğŸ› ï¸ å¼€å‘å·¥å…·
â”‚   â”œâ”€â”€ verify_structure.py           # é¡¹ç›®ç»“æ„éªŒè¯
â”‚   â”œâ”€â”€ benchmark.py                  # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”‚   â”œâ”€â”€ health_monitor.py             # å¥åº·ç›‘æ§å·¥å…·
â”‚   â””â”€â”€ config_generator.py           # é…ç½®ç”Ÿæˆå™¨
â”œâ”€â”€ tests/                            # âœ… æµ‹è¯•ç”¨ä¾‹
â”œâ”€â”€ docs/                             # ğŸ“š é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ generated_videos/                 # ğŸ“¹ ç”Ÿæˆè§†é¢‘å­˜å‚¨
â”œâ”€â”€ logs/                             # ğŸ“ æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ requirements.txt                  # ä¾èµ–æ¸…å•
â””â”€â”€ README.md                         # é¡¹ç›®æ–‡æ¡£
```

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶æ”¯æŒ

#### NPU (åä¸ºæ˜‡è…¾)
- **è®¾å¤‡å‹å·**ï¼š910B1/910B2/910B4 ç­‰æ˜‡è…¾èŠ¯ç‰‡
- **æ˜¾å­˜è¦æ±‚**ï¼šå•å¡ 24GB+ (T5 CPU æ¨¡å¼) / 32GB+ (æ ‡å‡†æ¨¡å¼)
- **é©±åŠ¨ç‰ˆæœ¬**ï¼šCANN 8.0+

#### GPU (NVIDIA)
- **è®¾å¤‡å‹å·**ï¼šRTX 3090/4090, A100, H100 ç­‰
- **æ˜¾å­˜è¦æ±‚**ï¼šå•å¡ 24GB+ (æ¨è 32GB+)
- **é©±åŠ¨ç‰ˆæœ¬**ï¼šCUDA 11.8+ / CUDA 12.0+

### ç³»ç»Ÿè¦æ±‚
- **CPU**ï¼š16+ æ ¸å¿ƒ (T5 CPU æ¨¡å¼å»ºè®® 32+ æ ¸å¿ƒ)
- **å†…å­˜**ï¼š64GB+ ç³»ç»Ÿå†…å­˜ (T5 CPU æ¨¡å¼éœ€è¦æ›´å¤š)
- **å­˜å‚¨**ï¼š200GB+ å¯ç”¨ç©ºé—´ (æ¨¡å‹ + è¾“å‡ºè§†é¢‘)
- **æ“ä½œç³»ç»Ÿ**ï¼šLinux (æ¨è Ubuntu 20.04+)

### è½¯ä»¶ç¯å¢ƒ
- **Python**ï¼š3.10+
- **PyTorch**ï¼š2.0+
- **è®¾å¤‡æ‰©å±•**ï¼štorch_npu (NPU) / torch (CUDA)

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### 1. é¡¹ç›®éªŒè¯

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd fastapi-multigpu-i2v

# éªŒè¯é¡¹ç›®ç»“æ„
python3 tools/verify_structure.py

# æ£€æµ‹è®¾å¤‡ç¯å¢ƒ
python3 scripts/debug/debug_device.py
```

### 2. ç¯å¢ƒé…ç½®

#### è‡ªåŠ¨é…ç½®ç”Ÿæˆ
```bash
# è‡ªåŠ¨ç”Ÿæˆæœ€ä¼˜é…ç½®
python3 tools/config_generator.py --preset production

# ä¸ºå¼€å‘ç¯å¢ƒç”Ÿæˆé…ç½®
python3 tools/config_generator.py --preset development --output .env.dev

# ä¸ºå†…å­˜å—é™ç¯å¢ƒç”Ÿæˆé…ç½®
python3 tools/config_generator.py --preset memory_efficient
```

#### æ‰‹åŠ¨ç¯å¢ƒé…ç½®
```bash
# NPU ç¯å¢ƒå˜é‡
export ALGO=0
export PYTORCH_NPU_ALLOC_CONF='expandable_segments:True'
export TASK_QUEUE_ENABLE=2
export HCCL_TIMEOUT=3600

# CUDA ç¯å¢ƒå˜é‡
export NCCL_TIMEOUT=3600
export CUDA_LAUNCH_BLOCKING=0

# é€šç”¨é…ç½®
export TOKENIZERS_PARALLELISM=false
export MASTER_ADDR=127.0.0.1
export MASTER_PORT=29500
```

### 3. ä¾èµ–å®‰è£…

```bash
# åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# NPU ç¯å¢ƒéªŒè¯
python3 -c "import torch_npu; print(f'NPU available: {torch_npu.npu.is_available()}')"

# CUDA ç¯å¢ƒéªŒè¯
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### 4. æ¨¡å‹å‡†å¤‡

```bash
# è®¾ç½®æ¨¡å‹è·¯å¾„
export MODEL_CKPT_DIR="/data/models/modelscope/hub/Wan-AI/Wan2.1-I2V-14B-720P"

# éªŒè¯æ¨¡å‹æ–‡ä»¶
ls -la $MODEL_CKPT_DIR/
```

### 5. å¯åŠ¨æœåŠ¡

#### ğŸš€ æ™ºèƒ½å¯åŠ¨ (æ¨è)
```bash
# è‡ªåŠ¨æ£€æµ‹è®¾å¤‡å¹¶å¯åŠ¨æœ€ä¼˜é…ç½®
chmod +x scripts/start_service_general.sh
./scripts/start_service_general.sh
```

#### ğŸ¯ è®¾å¤‡ä¸“ç”¨å¯åŠ¨
```bash
# NPU ä¸“ç”¨å¯åŠ¨ (åä¸ºæ˜‡è…¾)
chmod +x scripts/start_service_npu.sh
./scripts/start_service_npu.sh

# GPU ä¸“ç”¨å¯åŠ¨ (NVIDIA CUDA)
chmod +x scripts/start_service_cuda.sh  
./scripts/start_service_cuda.sh
```

#### ğŸ›ï¸ è‡ªå®šä¹‰é…ç½®å¯åŠ¨
```bash
# T5 CPU æ¨¡å¼ (èŠ‚çœæ˜¾å­˜)
T5_CPU=true MAX_CONCURRENT_TASKS=2 ./scripts/start_service_npu.sh

# é«˜æ€§èƒ½æ¨¡å¼
T5_CPU=false MAX_CONCURRENT_TASKS=4 ./scripts/start_service_cuda.sh

# è°ƒè¯•æ¨¡å¼
MAX_CONCURRENT_TASKS=1 TASK_TIMEOUT=3600 ./scripts/start_service_general.sh
```

### 6. æœåŠ¡éªŒè¯

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8088/health

# è®¾å¤‡ä¿¡æ¯
curl http://localhost:8088/device-info

# API æ–‡æ¡£
open http://localhost:8088/docs
```

## ğŸ” è°ƒè¯•å·¥å…·

### è®¾å¤‡æ£€æµ‹è°ƒè¯•
```bash
# æ£€æµ‹å¯ç”¨è®¾å¤‡
python3 scripts/debug/debug_device.py

# è®¾å¤‡è¯¦ç»†ä¿¡æ¯
python3 scripts/debug/debug_device.py --verbose
```

### T5 é¢„çƒ­è°ƒè¯•
```bash
# T5 CPU æ¨¡å¼é¢„çƒ­æµ‹è¯•
python3 scripts/debug/debug_t5_warmup.py --warmup-steps 3

# æŒ‡å®šæ¨¡å‹è·¯å¾„æµ‹è¯•
python3 scripts/debug/debug_t5_warmup.py --model-path /path/to/model
```

### å†…å­˜ç›‘æ§è°ƒè¯•
```bash
# æŸ¥çœ‹å½“å‰å†…å­˜çŠ¶æ€
python3 scripts/debug/debug_memory.py --mode status

# è¿ç»­ç›‘æ§ 60 ç§’
python3 scripts/debug/debug_memory.py --mode monitor --duration 60

# æ¨¡å‹åŠ è½½å†…å­˜æµ‹è¯•
python3 scripts/debug/debug_memory.py --mode model-test

# å†…å­˜å‹åŠ›æµ‹è¯•
python3 scripts/debug/debug_memory.py --mode stress-test
```

### ç®¡é“è°ƒè¯•
```bash
# æµ‹è¯•ç®¡é“åˆ›å»º
python3 scripts/debug/debug_pipeline.py

# æ‰¹é‡è°ƒè¯•æµ‹è¯•
bash scripts/debug/run_debug.sh
```

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### å¥åº·ç›‘æ§å·¥å…·
```bash
# å®æ—¶å¥åº·ç›‘æ§
python3 tools/health_monitor.py --url http://localhost:8088 --interval 30

# è¿ç»­ç›‘æ§ 1 å°æ—¶
python3 tools/health_monitor.py --duration 3600 --export health_report.json

# å‘Šè­¦ç›‘æ§
python3 tools/health_monitor.py --alert-on-error --alert-on-high-memory
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•
```bash
# åŸºç¡€æ€§èƒ½æµ‹è¯•
python3 tools/benchmark.py --requests 10 --concurrent 2

# å‹åŠ›æµ‹è¯•
python3 tools/benchmark.py --requests 50 --concurrent 5 --duration 1800

# å¯¼å‡ºæµ‹è¯•æŠ¥å‘Š
python3 tools/benchmark.py --export benchmark_report.json
```

### é…ç½®ç®¡ç†
```bash
# ç”Ÿæˆä¸åŒç¯å¢ƒé…ç½®
python3 tools/config_generator.py --preset development --output configs/dev.env
python3 tools/config_generator.py --preset production --output configs/prod.env
python3 tools/config_generator.py --preset high_quality --output configs/hq.env

# åˆ—å‡ºæ‰€æœ‰é¢„è®¾
python3 tools/config_generator.py --list-presets
```

## ğŸ“š API æ¥å£æ–‡æ¡£

### æ ¸å¿ƒæ¥å£

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ | è¯´æ˜ |
|------|------|------|------|
| `/video/submit` | POST | æäº¤è§†é¢‘ç”Ÿæˆä»»åŠ¡ | æ”¯æŒåˆ†å±‚å‚æ•°é…ç½® |
| `/video/status` | POST | æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ | å®æ—¶è¿›åº¦è·Ÿè¸ª |
| `/video/cancel` | POST | å–æ¶ˆä»»åŠ¡ | æ”¯æŒä¼˜é›…å–æ¶ˆ |
| `/health` | GET | æœåŠ¡å¥åº·æ£€æŸ¥ | å®Œæ•´ç³»ç»ŸçŠ¶æ€ |
| `/metrics` | GET | ç›‘æ§æŒ‡æ ‡ | æ€§èƒ½ç»Ÿè®¡æ•°æ® |
| `/device-info` | GET | è®¾å¤‡ä¿¡æ¯ | ç¡¬ä»¶é…ç½®è¯¦æƒ… |
| `/docs` | GET | API æ–‡æ¡£ | äº¤äº’å¼æ–‡æ¡£ |

### è¯·æ±‚å‚æ•°åˆ†å±‚

#### åŸºç¡€å‚æ•° (æ™®é€šç”¨æˆ·)
```json
{
  "prompt": "A cat playing in the garden",
  "image_url": "https://example.com/input.jpg",
  "quality_preset": "balanced"
}
```

#### è¿›é˜¶å‚æ•° (é«˜çº§ç”¨æˆ·)
```json
{
  "prompt": "A cat playing in the garden",
  "image_url": "https://example.com/input.jpg", 
  "quality_preset": "custom",
  "guidance_scale": 4.0,
  "infer_steps": 40,
  "sample_solver": "dpmpp"
}
```

#### ä¸“å®¶å‚æ•° (ç³»ç»Ÿç®¡ç†å‘˜)
```json
{
  "prompt": "A cat playing in the garden",
  "image_url": "https://example.com/input.jpg",
  "t5_fsdp": true,
  "use_attentioncache": true,
  "cache_start_step": 12
}
```

### å“åº”ç¤ºä¾‹

#### å¥åº·æ£€æŸ¥å“åº”
```json
{
  "status": "healthy",
  "timestamp": 1703847600.123,
  "uptime": 3600.5,
  "config": {
    "device_type": "npu",
    "device_count": 8,
    "t5_cpu": true,
    "max_concurrent": 2
  },
  "service": {
    "total_tasks": 15,
    "active_tasks": 1,
    "success_rate": 95.5
  },
  "resources": {
    "memory_usage": "68.5%",
    "available_slots": 1
  }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### T5 CPU æ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | T5 ä½ç½® | æ˜¾å­˜å ç”¨ | ç”Ÿæˆæ—¶é—´ | å¹¶å‘èƒ½åŠ› | é€‚ç”¨åœºæ™¯ |
|------|---------|----------|----------|----------|----------|
| æ ‡å‡†æ¨¡å¼ | NPU/GPU | ~28GB | 2-3åˆ†é’Ÿ | 4-5ä»»åŠ¡ | å¤§æ˜¾å­˜ç¯å¢ƒ |
| T5 CPU | CPU | ~20GB | 2.5-3.5åˆ†é’Ÿ | 2-3ä»»åŠ¡ | æ˜¾å­˜å—é™ç¯å¢ƒ |
| æ··åˆæ¨¡å¼ | è‡ªé€‚åº” | ~24GB | 2.2-3åˆ†é’Ÿ | 3-4ä»»åŠ¡ | å¹³è¡¡æ€§èƒ½ |

### è®¾å¤‡ç‰¹æ€§å¯¹æ¯”

| å¹³å° | ä¼˜åŠ¿ | åŠ£åŠ¿ | æ¨èé…ç½® |
|------|------|------|----------|
| **NPU (æ˜‡è…¾)** | é«˜èƒ½æ•ˆã€å¤§æ˜¾å­˜ | ç”Ÿæ€ç›¸å¯¹è¾ƒæ–° | T5_CPU=true, ä¿å®ˆå¹¶å‘ |
| **GPU (NVIDIA)** | æˆç†Ÿç”Ÿæ€ã€é«˜æ€§èƒ½ | åŠŸè€—è¾ƒé«˜ | T5_CPU=false, æ¿€è¿›å¹¶å‘ |

### æ€§èƒ½è°ƒä¼˜å»ºè®®

#### å†…å­˜ä¼˜åŒ–
```bash
# æ˜¾å­˜å—é™ç¯å¢ƒ
T5_CPU=true
DIT_FSDP=true
VAE_PARALLEL=false
MAX_CONCURRENT_TASKS=2
```

#### é€Ÿåº¦ä¼˜åŒ–  
```bash
# è¿½æ±‚æœ€é«˜æ€§èƒ½
T5_CPU=false
VAE_PARALLEL=true
USE_ATTENTION_CACHE=true
ULYSSES_SIZE=8
```

#### å¹³è¡¡é…ç½®
```bash
# æ€§èƒ½ä¸ç¨³å®šæ€§å¹³è¡¡
T5_CPU=true
DIT_FSDP=true
VAE_PARALLEL=true
MAX_CONCURRENT_TASKS=3
```

## ğŸ›ï¸ é…ç½®å‚æ•°

### ç¯å¢ƒå˜é‡é…ç½®

#### æ ¸å¿ƒé…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `T5_CPU` | false | T5 ç¼–ç å™¨æ˜¯å¦ä½¿ç”¨ CPU |
| `DIT_FSDP` | true | DiT æ¨¡å‹æ˜¯å¦ä½¿ç”¨ FSDP åˆ†ç‰‡ |
| `T5_FSDP` | false | T5 ç¼–ç å™¨æ˜¯å¦ä½¿ç”¨ FSDP åˆ†ç‰‡ |
| `VAE_PARALLEL` | true | VAE æ˜¯å¦å¹¶è¡Œç¼–è§£ç  |
| `ULYSSES_SIZE` | 8 | Ulysses åºåˆ—å¹¶è¡Œç»„æ•° |

#### æœåŠ¡é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | T5 CPU æ¨¡å¼é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|-------------------|------|
| `SERVER_HOST` | 0.0.0.0 | 0.0.0.0 | æœåŠ¡ç›‘å¬åœ°å€ |
| `SERVER_PORT` | 8088 | 8088 | æœåŠ¡ç«¯å£ |
| `MAX_CONCURRENT_TASKS` | 5 | 2 | æœ€å¤§å¹¶å‘ä»»åŠ¡æ•° |
| `TASK_TIMEOUT` | 1800 | 2400 | ä»»åŠ¡è¶…æ—¶æ—¶é—´(ç§’) |
| `CLEANUP_INTERVAL` | 300 | 300 | æ¸…ç†é—´éš”(ç§’) |
| `MAX_OUTPUT_DIR_SIZE` | 50 | 50 | æœ€å¤§è¾“å‡ºç›®å½•å¤§å°(GB) |
| `ALLOWED_HOSTS` | * | * | å…è®¸çš„ä¸»æœºåˆ—è¡¨ |
| `MODEL_CKPT_DIR` | /data/models/... | /data/models/... | æ¨¡å‹æ–‡ä»¶è·¯å¾„ |

#### é€šä¿¡é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | T5 CPU æ¨¡å¼è°ƒæ•´ | è¯´æ˜ |
|--------|--------|-----------------|------|
| `HCCL_TIMEOUT` | 1800 | 2400 | HCCL é€šä¿¡è¶…æ—¶(ç§’) |
| `HCCL_CONNECT_TIMEOUT` | 600 | 900 | HCCL è¿æ¥è¶…æ—¶(ç§’) |
| `HCCL_BUFFSIZE` | 512 | 256 | HCCL ç¼“å†²åŒºå¤§å° |

#### NPU ä¸“ç”¨ç¯å¢ƒå˜é‡

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `ALGO` | 0 | NPU ç®—æ³•é€‰æ‹© |
| `PYTORCH_NPU_ALLOC_CONF` | expandable_segments:True | NPU å†…å­˜åˆ†é…ç­–ç•¥ |
| `TASK_QUEUE_ENABLE` | 2 | NPU ä»»åŠ¡é˜Ÿåˆ—å¯ç”¨çº§åˆ« |
| `CPU_AFFINITY_CONF` | 1 | CPU äº²å’Œæ€§é…ç½® |
| `ASCEND_LAUNCH_BLOCKING` | 0 | NPU å¯åŠ¨é˜»å¡æ¨¡å¼ |
| `ASCEND_GLOBAL_LOG_LEVEL` | 1 | NPU å…¨å±€æ—¥å¿—çº§åˆ« |
| `NPU_VISIBLE_DEVICES` | 0,1,2,3,4,5,6,7 | å¯è§ NPU è®¾å¤‡ |
| `ASCEND_RT_VISIBLE_DEVICES` | 0,1,2,3,4,5,6,7 | NPU è¿è¡Œæ—¶å¯è§è®¾å¤‡ |

#### CUDA ä¸“ç”¨ç¯å¢ƒå˜é‡

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `NCCL_TIMEOUT` | 3600 | NCCL é€šä¿¡è¶…æ—¶(ç§’) |
| `CUDA_LAUNCH_BLOCKING` | 0 | CUDA å¯åŠ¨é˜»å¡æ¨¡å¼ |
| `NCCL_DEBUG` | INFO | NCCL è°ƒè¯•çº§åˆ« |
| `NCCL_IB_DISABLE` | 1 | ç¦ç”¨ InfiniBand |
| `NCCL_P2P_DISABLE` | 0 | ç¦ç”¨ç‚¹å¯¹ç‚¹é€šä¿¡ |
| `CUDA_VISIBLE_DEVICES` | 0,1,2,3,4,5,6,7 | å¯è§ CUDA è®¾å¤‡ |

#### CPU ä¼˜åŒ–é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | T5 CPU æ¨¡å¼å»ºè®® | è¯´æ˜ |
|--------|--------|-----------------|------|
| `OMP_NUM_THREADS` | 8 | 16 | OpenMP çº¿ç¨‹æ•° |
| `MKL_NUM_THREADS` | 8 | 16 | MKL çº¿ç¨‹æ•° |
| `OPENBLAS_NUM_THREADS` | 8 | 16 | OpenBLAS çº¿ç¨‹æ•° |
| `TOKENIZERS_PARALLELISM` | false | false | åˆ†è¯å™¨å¹¶è¡Œå¤„ç† |

### API è¯·æ±‚å‚æ•°

#### åŸºç¡€å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | èŒƒå›´ | è¯´æ˜ |
|------|------|--------|------|------|
| `prompt` | string | - | 10-500å­—ç¬¦ | è§†é¢‘æè¿°æç¤ºè¯ |
| `image_url` | string | - | HTTP/HTTPS | è¾“å…¥å›¾åƒåœ°å€ |
| `image_size` | string | "1280*720" | æ”¯æŒçš„åˆ†è¾¨ç‡ | è¾“å‡ºè§†é¢‘åˆ†è¾¨ç‡ |
| `num_frames` | int | 81 | 24-120 | è§†é¢‘å¸§æ•° |
| `guidance_scale` | float | 3.0 | 1.0-20.0 | CFG å¼•å¯¼ç³»æ•° |
| `infer_steps` | int | 30 | 20-100 | å»å™ªæ¨ç†æ­¥æ•° |
| `seed` | int | null | 0-2147483647 | éšæœºæ•°ç§å­ |
| `negative_prompt` | string | null | 0-500å­—ç¬¦ | è´Ÿé¢æç¤ºè¯ |

#### åˆ†å¸ƒå¼å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `vae_parallel` | bool | false | VAE å¹¶è¡Œç¼–è§£ç  |
| `ulysses_size` | int | 1 | Ulysses åºåˆ—å¹¶è¡Œç»„æ•° |
| `dit_fsdp` | bool | false | DiT æ¨¡å‹ FSDP åˆ†ç‰‡ |
| `t5_fsdp` | bool | false | T5 ç¼–ç å™¨ FSDP åˆ†ç‰‡ |
| `cfg_size` | int | 1 | CFG å¹¶è¡Œç»„æ•° |

#### æ€§èƒ½ä¼˜åŒ–å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `use_attentioncache` | bool | false | å¯ç”¨æ³¨æ„åŠ›ç¼“å­˜ |
| `start_step` | int | 12 | ç¼“å­˜èµ·å§‹æ­¥æ•° |
| `attentioncache_interval` | int | 4 | ç¼“å­˜æ›´æ–°é—´éš” |
| `end_step` | int | 37 | ç¼“å­˜ç»“æŸæ­¥æ•° |
| `sample_solver` | string | "unipc" | é‡‡æ ·ç®—æ³• |
| `sample_shift` | float | 5.0 | é‡‡æ ·åç§» |

### è´¨é‡é¢„è®¾é…ç½®

#### é¢„è®¾æ¨¡å¼å¯¹æ¯”

| é¢„è®¾æ¨¡å¼ | æ¨ç†æ­¥æ•° | å¼•å¯¼ç³»æ•° | é‡‡æ ·ç®—æ³• | é€‚ç”¨åœºæ™¯ |
|----------|----------|----------|----------|----------|
| `fast` | 20 | 2.5 | unipc | å¿«é€Ÿæµ‹è¯• |
| `balanced` | 30 | 3.0 | unipc | æ—¥å¸¸ä½¿ç”¨ |
| `high` | 50 | 4.0 | dpmpp | é«˜è´¨é‡è¾“å‡º |
| `custom` | ç”¨æˆ·å®šä¹‰ | ç”¨æˆ·å®šä¹‰ | ç”¨æˆ·å®šä¹‰ | è‡ªå®šä¹‰é…ç½® |

#### æ”¯æŒçš„åˆ†è¾¨ç‡

| åˆ†è¾¨ç‡ | æ¯”ä¾‹ | æ˜¾å­˜éœ€æ±‚ | ç”Ÿæˆæ—¶é—´ | æ¨èåœºæ™¯ |
|--------|------|----------|----------|----------|
| `1280*720` | 16:9 | æ ‡å‡† | æ ‡å‡† | æ¨ªå±è§†é¢‘ |
| `720*1280` | 9:16 | æ ‡å‡† | æ ‡å‡† | ç«–å±è§†é¢‘ |
| `1024*576` | 16:9 | è¾ƒä½ | è¾ƒå¿« | å¿«é€Ÿé¢„è§ˆ |
| `1920*1080` | 16:9 | è¾ƒé«˜ | è¾ƒæ…¢ | é«˜æ¸…è¾“å‡º |

#### æ”¯æŒçš„å¸§æ•°

| å¸§æ•° | æ—¶é•¿ (24fps) | æ˜¾å­˜éœ€æ±‚ | ç”Ÿæˆæ—¶é—´ | æ¨èåœºæ™¯ |
|------|--------------|----------|----------|----------|
| 41 | ~1.7ç§’ | è¾ƒä½ | è¾ƒå¿« | çŸ­è§†é¢‘ç‰‡æ®µ |
| 61 | ~2.5ç§’ | æ ‡å‡† | æ ‡å‡† | å¸¸è§„è§†é¢‘ |
| 81 | ~3.4ç§’ | æ ‡å‡† | æ ‡å‡† | é»˜è®¤é•¿åº¦ |
| 121 | ~5.0ç§’ | è¾ƒé«˜ | è¾ƒæ…¢ | é•¿è§†é¢‘ |

### é…ç½®æ¨¡æ¿ç¤ºä¾‹

#### å¼€å‘ç¯å¢ƒé…ç½®

```bash
# å¼€å‘æµ‹è¯•ç¯å¢ƒ
export T5_CPU=true
export MAX_CONCURRENT_TASKS=1
export TASK_TIMEOUT=3600
export DIT_FSDP=false
export VAE_PARALLEL=false
export ULYSSES_SIZE=1
export ASCEND_GLOBAL_LOG_LEVEL=0  # è¯¦ç»†æ—¥å¿—
```

#### ç”Ÿäº§ç¯å¢ƒé…ç½®

```bash
# ç”Ÿäº§ç¯å¢ƒ - NPU é«˜æ€§èƒ½
export T5_CPU=false
export MAX_CONCURRENT_TASKS=5
export TASK_TIMEOUT=1800
export DIT_FSDP=true
export VAE_PARALLEL=true
export ULYSSES_SIZE=8
export USE_ATTENTION_CACHE=true
```

#### å†…å­˜ä¼˜åŒ–é…ç½®

```bash
# å†…å­˜å—é™ç¯å¢ƒ
export T5_CPU=true
export MAX_CONCURRENT_TASKS=2
export TASK_TIMEOUT=2400
export DIT_FSDP=true
export VAE_PARALLEL=false
export ULYSSES_SIZE=4
export HCCL_TIMEOUT=3600
```

#### è°ƒè¯•é…ç½®

```bash
# è°ƒè¯•æ¨¡å¼
export T5_CPU=true
export MAX_CONCURRENT_TASKS=1
export TASK_TIMEOUT=7200
export ASCEND_GLOBAL_LOG_LEVEL=0
export ASCEND_LAUNCH_BLOCKING=1
export PYTORCH_NPU_ALLOC_CONF="expandable_segments:True"
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### API è°ƒç”¨ç¤ºä¾‹

#### åŸºç¡€ç¤ºä¾‹

```bash
# æäº¤è§†é¢‘ç”Ÿæˆä»»åŠ¡
curl -X POST "http://localhost:8088/video/submit" \
-H "Content-Type: application/json" \
-d '{
  "prompt": "A serene lake with a swan gracefully swimming",
  "image_url": "https://picsum.photos/1280/720",
  "num_frames": 81,
  "guidance_scale": 3.0,
  "infer_steps": 30
}'

# æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
curl -X POST "http://localhost:8088/video/status" \
-H "Content-Type: application/json" \
-d '{"requestId": "your-task-id-here"}'

# æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
curl "http://localhost:8088/health"

# è·å–ç›‘æ§æŒ‡æ ‡
curl "http://localhost:8088/metrics"
```

### Python å®¢æˆ·ç«¯ç¤ºä¾‹

```python
import requests
import time

# æäº¤ä»»åŠ¡
response = requests.post("http://localhost:8088/video/submit", json={
    "prompt": "A cat playing with a ball of yarn",
    "image_url": "https://example.com/cat.jpg",
    "num_frames": 81,
    "vae_parallel": True,
    "ulysses_size": 8,
    "use_attentioncache": True
})

if response.status_code == 429:
    print("æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•")
    exit()

task_id = response.json()["requestId"]
print(f"Task submitted: {task_id}")

# è½®è¯¢ä»»åŠ¡çŠ¶æ€
while True:
    status_response = requests.post("http://localhost:8088/video/status", 
                                   json={"requestId": task_id})
    status_data = status_response.json()
    
    print(f"Status: {status_data['status']}")
    
    if status_data["status"] == "Succeed":
        print(f"Video URL: {status_data['results']['video_url']}")
        break
    elif status_data["status"] == "Failed":
        print(f"Failed: {status_data['reason']}")
        break
    
    time.sleep(5)

# æ£€æŸ¥æœåŠ¡é…ç½®
health_response = requests.get("http://localhost:8088/health")
health_data = health_response.json()
print(f"T5 CPU mode: {health_data['config']['t5_cpu']}")
print(f"Max concurrent: {health_data['config']['max_concurrent']}")
```

### é”™è¯¯å¤„ç†ç¤ºä¾‹

```python
import requests

try:
    response = requests.post("http://localhost:8088/video/submit", json={
        "prompt": "test",  # å¤ªçŸ­ï¼Œä¼šè§¦å‘éªŒè¯é”™è¯¯
        "image_url": "invalid-url"
    })
    
    if response.status_code == 400:
        error_data = response.json()
        print(f"å‚æ•°é”™è¯¯: {error_data['error']} - {error_data['message']}")
    elif response.status_code == 429:
        print("æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•")
    elif response.status_code == 500:
        error_data = response.json()
        print(f"æœåŠ¡å™¨é”™è¯¯: {error_data['error']} - {error_data['message']}")
    else:
        task_id = response.json()["requestId"]
        print(f"ä»»åŠ¡æäº¤æˆåŠŸ: {task_id}")

except requests.RequestException as e:
    print(f"ç½‘ç»œé”™è¯¯: {str(e)}")
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. å¯åŠ¨å¤±è´¥
```bash
# æ£€æŸ¥ç¯å¢ƒ
python3 tools/verify_structure.py

# æ£€æŸ¥è®¾å¤‡
python3 scripts/debug/debug_device.py

# æ£€æŸ¥ä¾èµ–
pip install -r requirements.txt
```

#### 2. å†…å­˜ä¸è¶³
```bash
# ä½¿ç”¨ T5 CPU æ¨¡å¼
T5_CPU=true MAX_CONCURRENT_TASKS=1 ./scripts/start_service_npu.sh

# å†…å­˜ç›‘æ§
python3 scripts/debug/debug_memory.py --mode monitor
```

#### 3. T5 é¢„çƒ­å¤±è´¥
```bash
# T5 é¢„çƒ­è°ƒè¯•
python3 scripts/debug/debug_t5_warmup.py --warmup-steps 1

# å¢åŠ ç³»ç»Ÿå†…å­˜
echo "vm.swappiness=10" >> /etc/sysctl.conf
```

#### 4. è®¾å¤‡é€šä¿¡é”™è¯¯
```bash
# NPU ç¯å¢ƒé‡ç½®
export HCCL_TIMEOUT=7200
pkill -f i2v_api && sleep 10

# GPU ç¯å¢ƒé‡ç½®  
export NCCL_TIMEOUT=7200
nvidia-smi --gpu-reset
```

### è°ƒè¯•æµç¨‹

```bash
# 1. éªŒè¯é¡¹ç›®ç»“æ„
python3 tools/verify_structure.py

# 2. æ£€æµ‹ç¡¬ä»¶ç¯å¢ƒ
python3 scripts/debug/debug_device.py

# 3. æµ‹è¯• T5 é¢„çƒ­
python3 scripts/debug/debug_t5_warmup.py

# 4. ç›‘æ§å†…å­˜ä½¿ç”¨
python3 scripts/debug/debug_memory.py --mode status

# 5. å¯åŠ¨æœåŠ¡
./scripts/start_service_general.sh

# 6. å¥åº·æ£€æŸ¥
curl http://localhost:8088/health
```

## ğŸ”’ ç”Ÿäº§éƒ¨ç½²

### å®‰å…¨é…ç½®

```bash
# è®¿é—®æ§åˆ¶
export ALLOWED_HOSTS="api.company.com,*.company.com"

# èµ„æºé™åˆ¶
export MAX_CONCURRENT_TASKS=3
export TASK_TIMEOUT=1800
export MAX_OUTPUT_DIR_SIZE=100

# æ–‡ä»¶æƒé™
chmod 750 generated_videos/
chown www-data:www-data generated_videos/
```

### åå‘ä»£ç† (Nginx)

```nginx
upstream i2v_backend {
    server 127.0.0.1:8088;
}

server {
    listen 80;
    server_name api.company.com;
    
    client_max_body_size 100M;
    
    location / {
        proxy_pass http://i2v_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_read_timeout 1800s;
    }
    
    location /videos/ {
        alias /path/to/generated_videos/;
        expires 1d;
    }
}
```

### ç³»ç»ŸæœåŠ¡ (systemd)

```ini
[Unit]
Description=FastAPI Multi-GPU I2V Service
After=network.target

[Service]
Type=simple
User=i2v-service
WorkingDirectory=/opt/fastapi-multigpu-i2v
Environment=T5_CPU=true
Environment=MAX_CONCURRENT_TASKS=2
ExecStart=/opt/fastapi-multigpu-i2v/scripts/start_service_npu.sh
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

## ğŸ“‹ ä¾èµ–æ¸…å•

### æ ¸å¿ƒä¾èµ–
```txt
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.5.0
aiohttp>=3.9.0
torch>=2.0.0
transformers>=4.30.0
diffusers>=0.20.0
numpy>=1.24.0
Pillow>=10.0.0
```

### è®¾å¤‡ç‰¹å®š
```txt
# NPU ç¯å¢ƒ
torch_npu

# GPU ç¯å¢ƒ  
torch[cuda]

# å¯é€‰ä¾èµ–
psutil>=5.9.0        # ç³»ç»Ÿç›‘æ§
opencv-python>=4.8.0 # è§†é¢‘å¤„ç†
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¼€å‘æµç¨‹

1. **Fork é¡¹ç›®**
2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**: `git checkout -b feature/amazing-feature`
3. **éªŒè¯ä»£ç **: `python3 tools/verify_structure.py`
4. **è¿è¡Œæµ‹è¯•**: `python3 -m pytest tests/`
5. **æäº¤ä»£ç **: `git commit -m 'Add amazing feature'`
6. **æ¨é€åˆ†æ”¯**: `git push origin feature/amazing-feature`
7. **åˆ›å»º PR**

### ä»£ç è§„èŒƒ

```bash
# ä»£ç æ ¼å¼åŒ–
black src/ tools/ scripts/
isort src/ tools/ scripts/

# ç±»å‹æ£€æŸ¥
mypy src/

# æµ‹è¯•è¦†ç›–
pytest --cov=src tests/
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- **Wan AI Team** - æä¾› Wan2.1-I2V-14B-720P æ¨¡å‹
- **åä¸ºæ˜‡è…¾** - NPU ç¡¬ä»¶å’Œ CANN è½¯ä»¶æ ˆ
- **NVIDIA** - GPU ç¡¬ä»¶å’Œ CUDA è½¯ä»¶æ ˆ  
- **FastAPI** - é«˜æ€§èƒ½å¼‚æ­¥ Web æ¡†æ¶
- **PyTorch** - æ·±åº¦å­¦ä¹ æ¡†æ¶

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/your-repo/issues)
- **è®¨è®ºäº¤æµ**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **æŠ€æœ¯æ–‡æ¡£**: [é¡¹ç›® Wiki](https://github.com/your-repo/wiki)

## ğŸ¯ å¿«é€ŸéªŒè¯

```bash
# ä¸€é”®éªŒè¯å’Œå¯åŠ¨
git clone <repository-url>
cd fastapi-multigpu-i2v

# éªŒè¯ç¯å¢ƒ
python3 tools/verify_structure.py
python3 scripts/debug/debug_device.py

# å¯åŠ¨æœåŠ¡ (è‡ªåŠ¨æ£€æµ‹æœ€ä½³é…ç½®)
./scripts/start_service_general.sh

# æµ‹è¯• API
curl http://localhost:8088/health
curl -X POST http://localhost:8088/video/submit \
  -H "Content-Type: application/json" \
  -d '{"prompt": "test video", "image_url": "https://picsum.photos/1280/720"}'
```

**ğŸš€ å¼€å§‹ä½ çš„ AI è§†é¢‘ç”Ÿæˆä¹‹æ—…ï¼**