"""
FastAPI Multi-GPU I2V API Server
"""
import sys
import os
import logging
import asyncio
import uuid
from pathlib import Path
from typing import Dict, Any, Optional
import time
import json
from contextlib import asynccontextmanager
import traceback
from datetime import datetime

# ç¡®ä¿èƒ½æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•çš„ utils - åœ¨æ‰€æœ‰å…¶ä»–å¯¼å…¥ä¹‹å‰
def setup_project_paths():
    """è®¾ç½®é¡¹ç›®è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°æ‰€æœ‰æ¨¡å—"""
    current_file = Path(__file__).resolve()
    
    # è®¡ç®—è·¯å¾„ï¼šsrc/i2v_api.py -> é¡¹ç›®æ ¹ç›®å½•
    project_root = current_file.parent.parent
    src_root = current_file.parent
    utils_root = project_root / "utils"
    
    # è¦æ·»åŠ çš„è·¯å¾„åˆ—è¡¨
    paths_to_add = [
        str(project_root),      # é¡¹ç›®æ ¹ç›®å½•
        str(src_root),          # src ç›®å½•  
        str(utils_root)         # utils ç›®å½•ï¼ˆç›´æ¥æ·»åŠ ï¼‰
    ]
    
    # æ·»åŠ åˆ° sys.pathï¼Œé¿å…é‡å¤
    for path in paths_to_add:
        if os.path.exists(path) and path not in sys.path:
            sys.path.insert(0, path)
    
    return project_root, src_root, utils_root

# è®¾ç½®è·¯å¾„
project_root, src_root, utils_root = setup_project_paths()

# PyTorch ç›¸å…³å¯¼å…¥
import torch
import torch.distributed as dist

# FastAPI ç›¸å…³å¯¼å…¥
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles  # æ·»åŠ è¿™ä¸ªå¯¼å…¥
import uvicorn

# å¯¼å…¥é¡¹ç›®æ¨¡å— - ä½¿ç”¨ä¿®å¤çš„å¯¼å…¥æ–¹å¼
from schemas import (
    VideoSubmitRequest, VideoSubmitResponse,
    VideoStatusRequest, VideoStatusResponse,
    VideoCancelRequest, VideoCancelResponse,
    TaskStatus, VideoResults, HealthResponse, MetricsResponse
)

from pipelines import PipelineFactory, get_available_pipelines

# å¯¼å…¥è®¾å¤‡æ£€æµ‹å™¨ - å¤šç§å¯¼å…¥æ–¹å¼ï¼Œç¡®ä¿æˆåŠŸ
device_detector = None
DeviceType = None

try:
    # æ–¹æ³•1ï¼šæ ‡å‡†å¯¼å…¥
    from utils.device_detector import device_detector, DeviceType
except ImportError:
    try:
        # æ–¹æ³•2ï¼šç›´æ¥å¯¼å…¥
        import device_detector as dd
        device_detector = dd.device_detector
        DeviceType = dd.DeviceType
    except ImportError:
        try:
            # æ–¹æ³•3ï¼šä» utils åŒ…å¯¼å…¥
            from utils import device_detector as dd
            device_detector = dd.device_detector  
            DeviceType = dd.DeviceType
        except ImportError as e:
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯å¹¶é€€å‡º
            print(f"âŒ Failed to import device_detector in i2v_api.py: {e}")
            print(f"Project root: {project_root}")
            print(f"Utils root: {utils_root}")
            print(f"Utils exists: {utils_root.exists()}")
            print(f"device_detector.py exists: {(utils_root / 'device_detector.py').exists()}")
            print(f"Current sys.path: {sys.path[:5]}")
            print(f"Current working directory: {os.getcwd()}")
            sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ†å¸ƒå¼ç›¸å…³å…¨å±€å˜é‡
rank = int(os.environ.get("RANK", 0))
local_rank = int(os.environ.get("LOCAL_RANK", 0))
world_size = int(os.environ.get("WORLD_SIZE", 1))
startup_time = time.time()

# æœåŠ¡ç»Ÿè®¡
service_stats = {
    "total_tasks": 0,
    "successful_tasks": 0,
    "failed_tasks": 0,
    "cancelled_tasks": 0
}

# å…¨å±€å˜é‡
pipeline = None
task_manager = None
app_metrics = {
    "start_time": time.time(),
    "total_requests": 0,
    "active_tasks": 0,
    "completed_tasks": 0,
    "failed_tasks": 0,
    "total_generation_time": 0.0
}

# è§†é¢‘ç”ŸæˆæœåŠ¡ç±»
class VideoService:
    """è§†é¢‘ç”ŸæˆæœåŠ¡"""
    
    def __init__(self, pipeline_instance):
        self.pipeline = pipeline_instance
        self.tasks: Dict[str, Dict[str, Any]] = {}
        self.task_lock = asyncio.Lock()
        
        logger.info("VideoService initialized")
    
    async def submit_video_task(self, request: VideoSubmitRequest) -> str:
        """æäº¤è§†é¢‘ç”Ÿæˆä»»åŠ¡"""
        task_id = f"req_{uuid.uuid4().hex[:16]}"
        
        async with self.task_lock:
            # åˆ›å»ºä»»åŠ¡è®°å½•
            task_data = {
                "requestId": task_id,
                "status": TaskStatus.PENDING,
                "progress": 0,
                "message": "Task submitted successfully",
                "created_at": datetime.utcnow().isoformat() + "Z",
                "updated_at": datetime.utcnow().isoformat() + "Z",
                "request_params": request.model_dump(),
                "results": None,
                "reason": None,
                "elapsed_time": None
            }
            
            self.tasks[task_id] = task_data
            service_stats['total_tasks'] += 1
        
        # å¼‚æ­¥å¯åŠ¨ä»»åŠ¡
        asyncio.create_task(self._process_video_task(task_id, request))
        
        logger.info(f"Task {task_id} submitted successfully")
        return task_id
    
    async def _process_video_task(self, task_id: str, request: VideoSubmitRequest):
        """å¤„ç†è§†é¢‘ç”Ÿæˆä»»åŠ¡"""
        start_time = time.time()
        
        try:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
            await self._update_task_status(
                task_id, 
                TaskStatus.RUNNING, 
                10, 
                "Starting video generation..."
            )
            
            # è¿›åº¦å›è°ƒå‡½æ•°
            async def progress_callback(progress: int, total: int, message: str = ""):
                await self._update_task_status(task_id, TaskStatus.RUNNING, progress, message)
            
            # è°ƒç”¨ç®¡é“ç”Ÿæˆè§†é¢‘ - ä¿®å¤è°ƒç”¨æ–¹å¼
            logger.info(f"Starting video generation for task {task_id}")
            
            # ä½¿ç”¨æ­£ç¡®çš„ç®¡é“è°ƒç”¨æ–¹å¼
            result_path = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.pipeline.generate_video(request, task_id, progress_callback)
            )
            
            # ç”ŸæˆæˆåŠŸ
            elapsed_time = int(time.time() - start_time)
            
            # åˆ›å»ºç»“æœå¯¹è±¡
            video_results = VideoResults(
                video_url=f"http://localhost:8088/videos/{os.path.basename(result_path)}",
                video_path=result_path,
                duration=3.4,  # é»˜è®¤æ—¶é•¿
                frames=request.num_frames or 81,
                size=request.image_size or "1280*720",
                file_size=os.path.getsize(result_path) if os.path.exists(result_path) else 0
            )
            
            async with self.task_lock:
                if task_id in self.tasks:
                    self.tasks[task_id].update({
                        "status": TaskStatus.SUCCEED,
                        "progress": 100,
                        "message": "Video generation completed successfully",
                        "updated_at": datetime.utcnow().isoformat() + "Z",
                        "results": video_results.model_dump(),
                        "elapsed_time": elapsed_time
                    })
                    service_stats['successful_tasks'] += 1
            
            logger.info(f"Task {task_id} completed successfully in {elapsed_time}s")
            
        except asyncio.CancelledError:
            # ä»»åŠ¡è¢«å–æ¶ˆ
            await self._update_task_status(
                task_id, 
                TaskStatus.CANCELLED, 
                0, 
                "Task cancelled by user",
                reason="Task cancelled"
            )
            service_stats['cancelled_tasks'] += 1
            logger.info(f"Task {task_id} was cancelled")
            
        except Exception as e:
            # ä»»åŠ¡å¤±è´¥
            elapsed_time = int(time.time() - start_time)
            error_msg = str(e)
            
            await self._update_task_status(
                task_id, 
                TaskStatus.FAILED, 
                0, 
                f"Video generation failed: {error_msg}",
                reason=error_msg,
                elapsed_time=elapsed_time
            )
            service_stats['failed_tasks'] += 1
            logger.error(f"Task {task_id} failed after {elapsed_time}s: {error_msg}")
    
    async def _update_task_status(
        self, 
        task_id: str, 
        status: TaskStatus, 
        progress: int, 
        message: str,
        reason: Optional[str] = None,
        elapsed_time: Optional[int] = None
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        async with self.task_lock:
            if task_id in self.tasks:
                self.tasks[task_id].update({
                    "status": status,
                    "progress": progress,
                    "message": message,
                    "updated_at": datetime.utcnow().isoformat() + "Z"
                })
                
                if reason is not None:
                    self.tasks[task_id]["reason"] = reason
                
                if elapsed_time is not None:
                    self.tasks[task_id]["elapsed_time"] = elapsed_time
    
    async def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        async with self.task_lock:
            return self.tasks.get(task_id)
    
    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        async with self.task_lock:
            task = self.tasks.get(task_id)
            if not task:
                return False
            
            if task["status"] in [TaskStatus.SUCCEED, TaskStatus.FAILED, TaskStatus.CANCELLED]:
                return False
            
            # æ›´æ–°çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            task.update({
                "status": TaskStatus.CANCELLED,
                "progress": 0,
                "message": "Task cancelled by user",
                "updated_at": datetime.utcnow().isoformat() + "Z",
                "reason": "Cancelled by user"
            })
            
            service_stats['cancelled_tasks'] += 1
            
        logger.info(f"Task {task_id} cancelled")
        return True
    
    async def get_service_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        async with self.task_lock:
            active_tasks = len([t for t in self.tasks.values() 
                              if t["status"] in [TaskStatus.PENDING, TaskStatus.RUNNING]])
            
            return {
                **service_stats,
                "active_tasks": active_tasks,
                "success_rate": (service_stats['successful_tasks'] / max(service_stats['total_tasks'], 1)) * 100,
                "tasks_in_memory": len(self.tasks)
            }

# å…¨å±€æœåŠ¡å®ä¾‹
video_service = None

def init_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ"""
    if world_size == 1:
        logger.info("Single device mode")
        return True
    
    try:
        # æ£€æµ‹è®¾å¤‡ç±»å‹ - æ·»åŠ é”™è¯¯å¤„ç†
        try:
            device_type, device_count = device_detector.detect_device()
            logger.info(f"Detected device: {device_type.value} x {device_count}")
        except Exception as e:
            logger.error(f"Device detection failed: {e}")
            # ä½¿ç”¨ CPU ä½œä¸ºå¤‡ç”¨
            device_type = device_detector.DeviceType.CPU  # æˆ–è€…å¯¼å…¥ DeviceType
            device_count = 1
     
        # è®¾ç½®åç«¯
        if device_type.value == "npu":
            import torch_npu
            torch_npu.npu.set_device(local_rank)
            backend = "hccl"
        elif device_type.value == "cuda":
            torch.cuda.set_device(local_rank)
            backend = "nccl"
        else:
            backend = "gloo"
        
        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        if not dist.is_initialized():
            dist.init_process_group(
                backend=backend,
                rank=rank,
                world_size=world_size
            )
        
        # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
        dist.barrier()
        logger.info(f"Distributed initialized with {backend}")
        return True
        
    except Exception as e:
        logger.error(f"Distributed initialization failed: {e}")
        return False

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global pipeline, video_service
    
    try:
        logger.info("ğŸ”„ Starting application...")
        
        # åˆå§‹åŒ–åˆ†å¸ƒå¼
        if not init_distributed():
            logger.warning("Distributed initialization failed, continuing...")
        
        # åªåœ¨ä¸»è¿›ç¨‹ä¸­åˆå§‹åŒ–æœåŠ¡
        if rank == 0:
            # åˆ›å»ºç®¡é“
            logger.info("ğŸ­ Creating pipeline...")
            
            # è·å–é…ç½®
            ckpt_dir = os.environ.get('MODEL_CKPT_DIR', '/data/models/modelscope/hub/Wan-AI/Wan2.1-I2V-14B-720P')
            config = {
                'ckpt_dir': ckpt_dir,
                't5_cpu': os.environ.get('T5_CPU', 'true').lower() == 'true',
                'dit_fsdp': os.environ.get('DIT_FSDP', 'true').lower() == 'true',
                'vae_parallel': os.environ.get('VAE_PARALLEL', 'true').lower() == 'true'
            }
            
            pipeline = PipelineFactory.create_pipeline(**config)
            video_service = VideoService(pipeline)
            
            logger.info("âœ… Service initialized successfully")
        else:
            logger.info(f"â³ Worker {rank} waiting...")
        
        yield
        
    except Exception as e:
        logger.error(f"âŒ Startup failed: {e}")
        traceback.print_exc()
        yield
        
    finally:
        # æ¸…ç†èµ„æº
        if pipeline:
            try:
                pipeline.cleanup()
            except Exception as e:
                logger.warning(f"Pipeline cleanup warning: {e}")
        
        # æ¸…ç†åˆ†å¸ƒå¼
        if world_size > 1 and dist.is_initialized():
            try:
                dist.destroy_process_group()
            except Exception as e:
                logger.warning(f"Distributed cleanup warning: {e}")

# åˆ›å»ºåº”ç”¨
app = FastAPI(
    title="Multi-GPU I2V Generation API",
    description="Fast and scalable image-to-video generation service",
    version="1.0.0",
    lifespan=lifespan
)

# æ·»åŠ ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æœåŠ¡
os.makedirs("generated_videos", exist_ok=True)
app.mount("/videos", StaticFiles(directory="generated_videos"), name="videos")

# API è·¯ç”±
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        device_type, device_count = device_detector.detect_device()
    except Exception as e:
        logger.warning(f"Device detection failed in health check: {e}")
        device_type = None
        device_count = 0
    
    return HealthResponse(
        status="healthy" if video_service else "initializing",
        timestamp=time.time(),
        uptime=time.time() - startup_time,
        config={
            "rank": rank,
            "world_size": world_size,
            "local_rank": local_rank,
            "device_type": device_type.value if device_type else "unknown",
            "device_count": device_count
        },
        service=await video_service.get_service_stats() if video_service else {},
        resources={"memory": "unknown", "cpu_count": os.cpu_count()}
    )

@app.get("/metrics")
async def get_metrics():
    """è·å–ç›‘æ§æŒ‡æ ‡"""
    if not video_service:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    stats = await video_service.get_service_stats()
    
    return MetricsResponse(
        timestamp=time.time(),
        system={"uptime": time.time() - startup_time, "rank": rank},
        service=stats,
        tasks={"total": stats["total_tasks"], "active": stats["active_tasks"]},
        performance={"success_rate": stats["success_rate"]}
    )

@app.post("/submit", response_model=VideoSubmitResponse)
async def submit_video_generation(request: VideoSubmitRequest):
    """æäº¤è§†é¢‘ç”Ÿæˆä»»åŠ¡"""
    if rank != 0:
        raise HTTPException(status_code=503, detail="Only available on main process")
    
    if not video_service:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    try:
        task_id = await video_service.submit_video_task(request)
        return VideoSubmitResponse(
            requestId=task_id,
            status=TaskStatus.PENDING,
            message="Task submitted successfully",
            estimated_time=180
        )
    except Exception as e:
        logger.error(f"Submit error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/status", response_model=VideoStatusResponse)
async def get_video_status(request: VideoStatusRequest):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    if rank != 0:
        raise HTTPException(status_code=503, detail="Only available on main process")
    
    if not video_service:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    task_data = await video_service.get_task_status(request.requestId)
    
    if not task_data:
        raise HTTPException(status_code=404, detail="Task not found")
    
    return VideoStatusResponse(**task_data)

@app.post("/cancel", response_model=VideoCancelResponse)
async def cancel_video_generation(request: VideoCancelRequest):
    """å–æ¶ˆä»»åŠ¡"""
    if rank != 0:
        raise HTTPException(status_code=503, detail="Only available on main process")
    
    if not video_service:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    success = await video_service.cancel_task(request.requestId)
    
    if not success:
        raise HTTPException(status_code=404, detail="Task not found or cannot be cancelled")
    
    return VideoCancelResponse(
        requestId=request.requestId,
        status="cancelled",
        message="Task cancelled successfully"
    )

@app.get("/tasks")
async def get_task_list(status: Optional[str] = None):
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    if rank != 0:
        raise HTTPException(status_code=503, detail="Only available on main process")
    
    if not video_service:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥åœ¨VideoServiceä¸­å®ç°
    async with video_service.task_lock:
        tasks = list(video_service.tasks.values())
        
        if status:
            try:
                status_filter = TaskStatus(status)
                tasks = [t for t in tasks if t["status"] == status_filter]
            except ValueError:
                raise HTTPException(status_code=400, detail=f"Invalid status: {status}")
        
        tasks.sort(key=lambda x: x["created_at"], reverse=True)
        
        return {"tasks": tasks, "total": len(tasks), "filtered_by": status if status else "none"}

# ä¸»å‡½æ•°
def main():
    if rank == 0:
        # ä¸»è¿›ç¨‹è¿è¡ŒHTTPæœåŠ¡
        host = os.getenv("SERVER_HOST", "0.0.0.0")
        port = int(os.getenv("SERVER_PORT", 8088))
        
        logger.info(f"ğŸŒ Starting server on {host}:{port}")
        
        uvicorn.run(app, host=host, port=port, log_level="info", workers=1)
    else:
        # å·¥ä½œè¿›ç¨‹ç­‰å¾…
        logger.info(f"â³ Worker {rank} ready, waiting...")
        try:
            import time
            while True:
                time.sleep(60)  # å¿ƒè·³
                logger.debug(f"ğŸ’“ Worker {rank} alive")
        except KeyboardInterrupt:
            logger.info(f"ğŸ›‘ Worker {rank} stopping")

if __name__ == "__main__":
    main()